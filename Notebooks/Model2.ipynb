{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "import pandas as pd\r\n",
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "import torch.nn.functional as F\r\n",
    "import random\r\n",
    "import numpy as np\r\n",
    "import seaborn as sns\r\n",
    "from matplotlib import pyplot as plt\r\n",
    "# from pykeops.torch import LazyTensor\r\n",
    "from sklearn.cluster import KMeans"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "#Read Data, Drop unnecessary column and change - in rating to -1\r\n",
    "def getData(path):\r\n",
    "    supermarkets = pd.read_csv(path)\r\n",
    "    supermarkets.drop('Unnamed: 0', axis=1, inplace=True)\r\n",
    "    supermarkets.loc[supermarkets['rating']=='-', 'rating'] = -1\r\n",
    "    supermarkets.loc[supermarkets['rating']=='0.0', 'rating'] = -1\r\n",
    "    supermarkets.rating = supermarkets.rating.map(float)\r\n",
    "    return supermarkets\r\n",
    "def cluster():\r\n",
    "    #Try Kmeans to fill out the missing values\r\n",
    "    km = KMeans(n_clusters=6)\r\n",
    "    x = supermarkets.drop(['rating', 'business_status', 'name', 'latitude', 'longitude', 'bus_stations','train_stations'],axis=1).values\r\n",
    "    yp = km.fit_predict(x)\r\n",
    "    supermarkets[['rating', 'predicted_rating']].head(30)\r\n",
    "def generateRating(supermarkets, coefficient):\r\n",
    "    data = supermarkets.drop(['business_status','name','latitude','longitude','bus_stations','train_stations'],axis=1)\r\n",
    "    data=(data-data.mean())/data.std()\r\n",
    "    data['new_rating'] = 0.4 * data['rating'] + 0.4 * data['atms'] + 0.5 *data['banks'] \\\r\n",
    "              + 0.4 * data['churches'] + 0.4 * data['gas_stations'] + 0.5 *data['hospitals'] \\\r\n",
    "              + 0.4 * data['mosques'] + 0.4 * data['pharmacies'] + 0.5 *data['restaurants'] \\\r\n",
    "              + 0.4 * data['schools'] + 0.4 * data['Males'] + 0.5 *data['Females'] \\\r\n",
    "              + 0.4 * data['Children'] + 0.4 * data['Working'] + 0.5 *data['Elderly']\r\n",
    "    data.drop('rating', axis=1, inplace=True)\r\n",
    "    return data\r\n",
    "data =getData('supermarkets_cleaned_with_popn_v2.csv')\r\n",
    "data = generateRating(data, None)\r\n",
    "data.head()\r\n",
    "\r\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>atms</th>\n",
       "      <th>banks</th>\n",
       "      <th>churches</th>\n",
       "      <th>gas_stations</th>\n",
       "      <th>hospitals</th>\n",
       "      <th>mosques</th>\n",
       "      <th>pharmacies</th>\n",
       "      <th>restaurants</th>\n",
       "      <th>schools</th>\n",
       "      <th>Males</th>\n",
       "      <th>Females</th>\n",
       "      <th>Children</th>\n",
       "      <th>Working</th>\n",
       "      <th>Elderly</th>\n",
       "      <th>new_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.518810</td>\n",
       "      <td>-0.862814</td>\n",
       "      <td>-0.633079</td>\n",
       "      <td>0.080125</td>\n",
       "      <td>-0.723125</td>\n",
       "      <td>-1.040533</td>\n",
       "      <td>-1.092615</td>\n",
       "      <td>-0.950018</td>\n",
       "      <td>-1.287014</td>\n",
       "      <td>0.317576</td>\n",
       "      <td>0.377080</td>\n",
       "      <td>0.305240</td>\n",
       "      <td>0.390954</td>\n",
       "      <td>-0.536509</td>\n",
       "      <td>-3.053376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.813666</td>\n",
       "      <td>0.482228</td>\n",
       "      <td>0.444106</td>\n",
       "      <td>-0.705832</td>\n",
       "      <td>0.962816</td>\n",
       "      <td>-0.033729</td>\n",
       "      <td>0.122986</td>\n",
       "      <td>0.307916</td>\n",
       "      <td>0.520830</td>\n",
       "      <td>0.775200</td>\n",
       "      <td>0.920317</td>\n",
       "      <td>0.630812</td>\n",
       "      <td>0.900079</td>\n",
       "      <td>1.638179</td>\n",
       "      <td>4.154013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.709163</td>\n",
       "      <td>-0.563915</td>\n",
       "      <td>-0.363783</td>\n",
       "      <td>-0.312854</td>\n",
       "      <td>-0.835521</td>\n",
       "      <td>1.224775</td>\n",
       "      <td>-0.397986</td>\n",
       "      <td>-0.525261</td>\n",
       "      <td>-0.081785</td>\n",
       "      <td>-0.125006</td>\n",
       "      <td>-0.274286</td>\n",
       "      <td>-0.264675</td>\n",
       "      <td>-0.202537</td>\n",
       "      <td>0.772058</td>\n",
       "      <td>-1.521088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.518810</td>\n",
       "      <td>0.033881</td>\n",
       "      <td>-0.094487</td>\n",
       "      <td>-0.705832</td>\n",
       "      <td>-0.385936</td>\n",
       "      <td>-1.040533</td>\n",
       "      <td>0.817616</td>\n",
       "      <td>1.092083</td>\n",
       "      <td>0.445503</td>\n",
       "      <td>0.317576</td>\n",
       "      <td>0.377080</td>\n",
       "      <td>0.305240</td>\n",
       "      <td>0.390954</td>\n",
       "      <td>-0.536509</td>\n",
       "      <td>-0.057230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.518810</td>\n",
       "      <td>0.382595</td>\n",
       "      <td>1.386643</td>\n",
       "      <td>1.259060</td>\n",
       "      <td>0.962816</td>\n",
       "      <td>-0.788832</td>\n",
       "      <td>0.122986</td>\n",
       "      <td>0.389600</td>\n",
       "      <td>-0.006458</td>\n",
       "      <td>0.317576</td>\n",
       "      <td>0.377080</td>\n",
       "      <td>0.305240</td>\n",
       "      <td>0.390954</td>\n",
       "      <td>-0.536509</td>\n",
       "      <td>1.460715</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       atms     banks  churches  gas_stations  hospitals   mosques  \\\n",
       "0 -0.518810 -0.862814 -0.633079      0.080125  -0.723125 -1.040533   \n",
       "1  0.813666  0.482228  0.444106     -0.705832   0.962816 -0.033729   \n",
       "2 -0.709163 -0.563915 -0.363783     -0.312854  -0.835521  1.224775   \n",
       "3 -0.518810  0.033881 -0.094487     -0.705832  -0.385936 -1.040533   \n",
       "4 -0.518810  0.382595  1.386643      1.259060   0.962816 -0.788832   \n",
       "\n",
       "   pharmacies  restaurants   schools     Males   Females  Children   Working  \\\n",
       "0   -1.092615    -0.950018 -1.287014  0.317576  0.377080  0.305240  0.390954   \n",
       "1    0.122986     0.307916  0.520830  0.775200  0.920317  0.630812  0.900079   \n",
       "2   -0.397986    -0.525261 -0.081785 -0.125006 -0.274286 -0.264675 -0.202537   \n",
       "3    0.817616     1.092083  0.445503  0.317576  0.377080  0.305240  0.390954   \n",
       "4    0.122986     0.389600 -0.006458  0.317576  0.377080  0.305240  0.390954   \n",
       "\n",
       "    Elderly  new_rating  \n",
       "0 -0.536509   -3.053376  \n",
       "1  1.638179    4.154013  \n",
       "2  0.772058   -1.521088  \n",
       "3 -0.536509   -0.057230  \n",
       "4 -0.536509    1.460715  "
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "# data.to_csv('data_regression.csv',index=False, header=False)\r\n",
    "data.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1388, 15)"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# pytorch mlp for regression\r\n",
    "from numpy import vstack\r\n",
    "from numpy import sqrt\r\n",
    "from pandas import read_csv\r\n",
    "from sklearn.metrics import mean_squared_error\r\n",
    "from torch.utils.data import Dataset\r\n",
    "from torch.utils.data import DataLoader\r\n",
    "from torch.utils.data import random_split\r\n",
    "from torch import Tensor\r\n",
    "from torch.nn import Linear\r\n",
    "from torch.nn import Sigmoid\r\n",
    "from torch.nn import Module\r\n",
    "from torch.optim import SGD\r\n",
    "from torch.nn import MSELoss\r\n",
    "from torch.nn.init import xavier_uniform_\r\n",
    "\r\n",
    "# dataset definition\r\n",
    "class CSVDataset(Dataset):\r\n",
    "    # load the dataset\r\n",
    "    def __init__(self, path):\r\n",
    "        # load the csv file as a dataframe\r\n",
    "        df = read_csv(path, header=None)\r\n",
    "        # store the inputs and outputs\r\n",
    "        self.X = df.values[:, :-1].astype('float32')\r\n",
    "        self.y = df.values[:, -1].astype('float32')\r\n",
    "        # ensure target has the right shape\r\n",
    "        self.y = self.y.reshape((len(self.y), 1))\r\n",
    "\r\n",
    "    # number of rows in the dataset\r\n",
    "    def __len__(self):\r\n",
    "        return len(self.X)\r\n",
    "\r\n",
    "    # get a row at an index\r\n",
    "    def __getitem__(self, idx):\r\n",
    "        return [self.X[idx], self.y[idx]]\r\n",
    "\r\n",
    "    # get indexes for train and test rows\r\n",
    "    def get_splits(self, n_test=0.33):\r\n",
    "        # determine sizes\r\n",
    "        test_size = round(n_test * len(self.X))\r\n",
    "        train_size = len(self.X) - test_size\r\n",
    "        # calculate the split\r\n",
    "        return random_split(self, [train_size, test_size])\r\n",
    "\r\n",
    "# model definition\r\n",
    "class MLP(Module):\r\n",
    "    # define model elements\r\n",
    "    def __init__(self, n_inputs):\r\n",
    "        super(MLP, self).__init__()\r\n",
    "        # input to first hidden layer\r\n",
    "        self.hidden1 = Linear(n_inputs, 10)\r\n",
    "        xavier_uniform_(self.hidden1.weight)\r\n",
    "        self.act1 = Sigmoid()\r\n",
    "        # second hidden layer\r\n",
    "        self.hidden2 = Linear(10, 8)\r\n",
    "        xavier_uniform_(self.hidden2.weight)\r\n",
    "        self.act2 = Sigmoid()\r\n",
    "        # third hidden layer and output\r\n",
    "        self.hidden3 = Linear(8, 1)\r\n",
    "        xavier_uniform_(self.hidden3.weight)\r\n",
    "\r\n",
    "    # forward propagate input\r\n",
    "    def forward(self, X):\r\n",
    "        # input to first hidden layer\r\n",
    "        X = self.hidden1(X)\r\n",
    "        X = self.act1(X)\r\n",
    "         # second hidden layer\r\n",
    "        X = self.hidden2(X)\r\n",
    "        X = self.act2(X)\r\n",
    "        # third hidden layer and output\r\n",
    "        X = self.hidden3(X)\r\n",
    "        return X\r\n",
    "\r\n",
    "# prepare the dataset\r\n",
    "def prepare_data(path):\r\n",
    "    # load the dataset\r\n",
    "    dataset = CSVDataset(path)\r\n",
    "    # calculate split\r\n",
    "    train, test = dataset.get_splits()\r\n",
    "    # prepare data loaders\r\n",
    "    train_dl = DataLoader(train, batch_size=32, shuffle=True)\r\n",
    "    test_dl = DataLoader(test, batch_size=1024, shuffle=False)\r\n",
    "    return train_dl, test_dl\r\n",
    "\r\n",
    "# train the model\r\n",
    "def train_model(train_dl, model):\r\n",
    "    # define the optimization\r\n",
    "    criterion = MSELoss()\r\n",
    "    optimizer = SGD(model.parameters(), lr=0.01, momentum=0.9)\r\n",
    "    # enumerate epochs\r\n",
    "    for epoch in range(500):\r\n",
    "        # enumerate mini batches\r\n",
    "        for i, (inputs, targets) in enumerate(train_dl):\r\n",
    "            # clear the gradients\r\n",
    "            optimizer.zero_grad()\r\n",
    "            # compute the model output\r\n",
    "            yhat = model(inputs)\r\n",
    "            # calculate loss\r\n",
    "            loss = criterion(yhat, targets)\r\n",
    "            # credit assignment\r\n",
    "            loss.backward()\r\n",
    "            # update model weights\r\n",
    "            optimizer.step()\r\n",
    "\r\n",
    "# evaluate the model\r\n",
    "def evaluate_model(test_dl, model):\r\n",
    "    predictions, actuals = list(), list()\r\n",
    "    for i, (inputs, targets) in enumerate(test_dl):\r\n",
    "        # evaluate the model on the test set\r\n",
    "        yhat = model(inputs)\r\n",
    "        # retrieve numpy array\r\n",
    "        yhat = yhat.detach().numpy()\r\n",
    "        actual = targets.numpy()\r\n",
    "        actual = actual.reshape((len(actual), 1))\r\n",
    "        # store\r\n",
    "        predictions.append(yhat)\r\n",
    "        actuals.append(actual)\r\n",
    "    predictions, actuals = vstack(predictions), vstack(actuals)\r\n",
    "    # calculate mse\r\n",
    "    mse = mean_squared_error(actuals, predictions)\r\n",
    "    return mse\r\n",
    "\r\n",
    "# make a class prediction for one row of data\r\n",
    "def predict(row, model):\r\n",
    "    # convert row to data\r\n",
    "    row = Tensor([row])\r\n",
    "    # make prediction\r\n",
    "    yhat = model(row)\r\n",
    "    # retrieve numpy array\r\n",
    "    yhat = yhat.detach().numpy()\r\n",
    "    return yhat\r\n",
    "\r\n",
    "# prepare the data\r\n",
    "path = 'data_regression.csv'\r\n",
    "train_dl, test_dl = prepare_data(path)\r\n",
    "print(len(train_dl.dataset), len(test_dl.dataset))\r\n",
    "# define the network\r\n",
    "model = MLP(15)\r\n",
    "# train the model\r\n",
    "train_model(train_dl, model)\r\n",
    "# evaluate the model\r\n",
    "mse = evaluate_model(test_dl, model)\r\n",
    "print('MSE: %.3f, RMSE: %.3f' % (mse, sqrt(mse)))\r\n",
    "# make a single prediction (expect class=1)\r\n",
    "# row = [0.00632,18.00,2.310,0,0.5380,6.5750,65.20,4.0900,1,296.0,15.30,396.90,4.98]\r\n",
    "# yhat = predict(row, model)\r\n",
    "# torch.save(model, 'lin_model.h5')\r\n",
    "# print('Predicted: %.3f' % yhat)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "368 182\n",
      "MSE: 0.007, RMSE: 0.085\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "row = [-0.593369154105506,-1.0217534331271696,-0.5337476389488008,0.8366289313353069,-0.5359795978170312,-0.26459234552837585,0.09537639766319944,-1.0175072314624598,-0.8610067601718433,0.45093392563549883,0.4835249295159094,0.605984487187577,0.41832272900476153,-0.33808441144945045,-0.8495007528106202]\r\n",
    "# -2.3514740192009241\r\n",
    "yhat = predict(row, model)\r\n",
    "yhat"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[-2.37537]], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "import torch\r\n",
    "torch.save(model, 'regression_model.h5')\r\n",
    "# model = torch.load('regression_model.h5')\r\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[-2.37537]], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6206300f00309e1df0e24b30e854b672d1b1249eee1b3bb6290a9fe247a2160c"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit ('intel': conda)"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}