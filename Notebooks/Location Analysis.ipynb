{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "7447ceb5e57b7b41884341f18cb31c61c6fd14c0ab5d8d1b1e7ce7ba61cc3137"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "### Gathering Nearby Locations"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect Required Features\n",
    "# Scrap google maps for each feature\n",
    "# Preprocess and Convert to a dataframe\n",
    "# Extract and return counts of each feature "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: googlemaps in /home/noumenon/anaconda3/lib/python3.8/site-packages (4.4.5)\n",
      "Requirement already satisfied: requests<3.0,>=2.20.0 in /home/noumenon/anaconda3/lib/python3.8/site-packages (from googlemaps) (2.24.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/noumenon/.local/lib/python3.8/site-packages (from requests<3.0,>=2.20.0->googlemaps) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/noumenon/anaconda3/lib/python3.8/site-packages (from requests<3.0,>=2.20.0->googlemaps) (2020.6.20)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /home/noumenon/.local/lib/python3.8/site-packages (from requests<3.0,>=2.20.0->googlemaps) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/noumenon/anaconda3/lib/python3.8/site-packages (from requests<3.0,>=2.20.0->googlemaps) (1.25.11)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install googlemaps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import Point\n",
    "from shapely.geometry.polygon import Polygon\n",
    "import pandas as pd\n",
    "import googlemaps\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initializeGoogleMaps(API_KEY):\n",
    "    return googlemaps.Client(API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanData(data_list):\n",
    "    # Inner Functions for dataframe cleaning\n",
    "    def lat(row):\n",
    "        if 'location' in row:\n",
    "            return row['location']['lat']\n",
    "        return None\n",
    "    def lng(row):\n",
    "        if 'location' in row:\n",
    "            return row['location']['lng']\n",
    "        return None\n",
    "    def check(row, col):\n",
    "        if col in row:\n",
    "            return 1\n",
    "        return 0\n",
    "\n",
    "    df = pd.DataFrame(data_list)    \n",
    "    if len(data_list)>0:\n",
    "        cleaned_df = df.drop(['photos', 'icon', 'scope', 'permanently_closed', 'opening_hours', 'reference', 'plus_code', 'user_ratings_total', 'vicinity'], axis=1, errors='ignore')    \n",
    "        cleaned_df['latitude'] = cleaned_df['geometry'].apply(lat)\n",
    "        cleaned_df['longitude'] = cleaned_df['geometry'].apply(lng)\n",
    "        cleaned_df = cleaned_df.drop(['geometry', 'types'],axis=1, errors='ignore')\n",
    "        print('Before dropping duplicates, the size was,',len(cleaned_df))\n",
    "        cleaned_df.sort_values(\"place_id\", inplace=True)\n",
    "        cleaned_df.drop_duplicates(inplace=True)\n",
    "        print('After dropping duplicates, the size was,',len(cleaned_df))\n",
    "        return cleaned_df\n",
    "    else:\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractFeatures(options, latitude, longitude):\n",
    "    dataframes = []\n",
    "    for opt in options:\n",
    "        data_list = []\n",
    "        params = {\n",
    "            'location':[latitude, longitude],\n",
    "            'radius':1000,\n",
    "            'type': opt\n",
    "        }\n",
    "\n",
    "        first_page = gmaps.places_nearby(**params)\n",
    "        \n",
    "        second_page = {'results':[]}\n",
    "        third_page = {'results':[]}\n",
    "        \n",
    "        #Fetching the second page if there is any\n",
    "        if 'next_page_token' in first_page:\n",
    "            params['page_token'] = first_page['next_page_token']\n",
    "            time.sleep(2)\n",
    "            second_page = gmaps.places_nearby(**params)\n",
    "        \n",
    "        #Fetching the third or last page if there is any\n",
    "        if 'next_page_token' in second_page:\n",
    "            params['page_token'] = second_page['next_page_token']\n",
    "            time.sleep(2)\n",
    "            third_page = gmaps.places_nearby(**params)\n",
    "        \n",
    "        data_list.extend(first_page['results'])\n",
    "        data_list.extend(second_page['results'])\n",
    "        data_list.extend(third_page['results'])\n",
    "        cleaned_data = cleanData(data_list)\n",
    "        if cleaned_data.shape[0]>0:\n",
    "            dataframes.append((opt, cleaned_data))\n",
    "    return dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collectNearbyPlaces(current_features, latitude, longitude):\n",
    "    dataframes = extractFeatures(current_features, latitude, longitude)\n",
    "    nearby_places = {}\n",
    "    for key in current_features:\n",
    "        nearby_places[key] = 0\n",
    "    for key, df in dataframes:\n",
    "        if 'permanently_closed' in df.columns:\n",
    "            df = df[df['permanently_closed']!=True]\n",
    "        nearby_places[key]0 = df.shape[0]\n",
    "    return nearby_places"
   ]
  },
  {
   "source": [
    "### Extract Population"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Read Population JSON file\n",
    "# Iterate over each subcity to find one that contains the coordinate within it\n",
    "# Return the population of males and females when found"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and read Population file\n",
    "def importPopulationFile(location = '../Data/Population_per_subcity.json'):\n",
    "    script_dir = os.path.dirname(\"__file__\")\n",
    "    subcity_population_json = os.path.join(script_dir, location )\n",
    "    subcity_population = open(subcity_population_json,)\n",
    "    subcity_population_data = json.load(subcity_population)\n",
    "    return subcity_population_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Given a coordinate, using the population json return the subcity population for the coordinate\n",
    "def determineSubcityAndAddPopulation(latitude, longitude):\n",
    "    subcity_population_data = importPopulationFile()\n",
    "\n",
    "    for subcity in subcity_population_data:\n",
    "        point = Point(latitude,longitude)\n",
    "        polygon = Polygon([(i,j) for i, j in subcity_population_data[subcity]['coordinates']])\n",
    "        if polygon.contains(point):\n",
    "            total_males = total_females = 0\n",
    "            for age in subcity_population_data[subcity]['population']:\n",
    "              total_males += subcity_population_data[subcity]['population'][age]['Males']  \n",
    "              total_females += subcity_population_data[subcity]['population'][age]['Females']  \n",
    "            return [total_males, total_females]\n",
    "    return [0,0]"
   ]
  },
  {
   "source": [
    "### Merging Both of them Together"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Before dropping duplicates, the size was, 2\n",
      "After dropping duplicates, the size was, 2\n",
      "Before dropping duplicates, the size was, 49\n",
      "After dropping duplicates, the size was, 49\n",
      "Before dropping duplicates, the size was, 1\n",
      "After dropping duplicates, the size was, 1\n",
      "Before dropping duplicates, the size was, 39\n",
      "After dropping duplicates, the size was, 39\n",
      "Before dropping duplicates, the size was, 5\n",
      "After dropping duplicates, the size was, 5\n",
      "Before dropping duplicates, the size was, 41\n",
      "After dropping duplicates, the size was, 41\n",
      "Before dropping duplicates, the size was, 5\n",
      "After dropping duplicates, the size was, 5\n",
      "Before dropping duplicates, the size was, 26\n",
      "After dropping duplicates, the size was, 26\n",
      "Before dropping duplicates, the size was, 60\n",
      "After dropping duplicates, the size was, 60\n",
      "Before dropping duplicates, the size was, 57\n",
      "After dropping duplicates, the size was, 57\n",
      "{'atm': [2], 'bank': [49], 'bus_station': [1], 'church': [39], 'gas_station': [5], 'hospital': [41], 'mosque': [5], 'pharmacy': [26], 'restaurant': [60], 'school': [57], 'train_station': [0], 'Males': 103500, 'Females': 117734}\n"
     ]
    }
   ],
   "source": [
    "def extractData(current_features, latitude, longitude):\n",
    "    nearby_places = collectNearbyPlaces(current_features, latitude, longitude)\n",
    "    males, females = determineSubcityAndAddPopulation(latitude, longitude)\n",
    "    nearby_places['Males'] = males\n",
    "    nearby_places['Females'] = females\n",
    "    return nearby_places\n",
    "\n",
    "gmaps = initializeGoogleMaps('')\n",
    "\n",
    "current_features = ['atm','bank','bus_station','church','gas_station','hospital','mosque','pharmacy','restaurant','school','train_station']\n",
    "latitude, longitude = 8.9806, 38.7578\n",
    "\n",
    "extracted_data = extractData(current_features, latitude, longitude)\n",
    "print(extracted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}